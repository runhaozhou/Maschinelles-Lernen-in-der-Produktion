{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 2.2 - Regressionsbäume am Beispiel Presshärten\n",
    "VO Maschinelles Lernen in der Produktion, WS2020/21, Moritz von Unold, Richard Lux, Felix Soest\n",
    "\n",
    "#### In diesem Notebook wird das Verfahren Regressionsbäume anhand des Anwendungsbeispiels Presshärten geübt.\n",
    "\n",
    "Auf dem Datensatz des Umformprozesses soll bei gegebenen Prozess-Parametern die Bauteilhärte vorhergesagt werden. Die Vorhersage soll direkt in der Fertigungslinie manuell durchgeführt werden. \n",
    "\n",
    "Um den Regressionsbaum in der Fertigung anwenden zu können darf dieser nicht zu groß werden (Knotenanzahl!).\n",
    "Eine möglichst hohe Genauigkeit bei akzeptabler Baumgröße ist gesucht.\n",
    "\n",
    "Es werden 4 Regressionsbäume mit verschiedenen Modellparametern trainiert. Diese werden validiert und gegeneinander verglichen. Dann wird 1 Regressionsbaum ausgewählt und getestet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Bibliotheken importieren\n",
    "\n",
    "#### 1. Daten erfassen\n",
    "- Daten importieren\n",
    "\n",
    "#### 2. Daten erkunden\n",
    "- TODO\n",
    "- TODO\n",
    "\n",
    "#### 3. Daten vorbereiten\n",
    "- Daten in Trainings-, Validierungs- und Testdaten aufteilen\n",
    "\n",
    "#### 4. Modelle bilden \n",
    "- Mögliche Hyperparameter (Modell-Parameter) anzeigen\n",
    "- 4 Modelle erstellen und trainieren\n",
    "- Anzeigen der Regressionsbäume\n",
    "- Bewertung des Trainings - Graph (y/y_pred)\n",
    "- Bewertung des Trainings - MAE\n",
    "\n",
    "#### 5. Modelle validieren\n",
    "- Validierung der Modelle - Graph (y/y_pred)\n",
    "- Validierung der Modelle - MAE\n",
    "- Auswahl eines Vorzugsmodells\n",
    "\n",
    "#### 6. Modell testen & anwenden\n",
    "- Bewertung des Vorzugsmodells - Graph (y/y_pred)\n",
    "- Bewertung der Vorzugsmodells - MAE\n",
    "- Erkenntnisse aus dem Modell/Nutzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Code-Block\n",
    "\n",
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren\n",
    "\n",
    "TODO:\n",
    "- Wähle eine Zahl zwischen 1 und 100 für die Generierung deiner spezifischen Zufallszahlen  (1. Code-Block - Zeile 8)\n",
    "- Ausführen des 1. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Code-Block\n",
    "\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Lade Datensatz\n",
    "df = pd.read_excel(\"Daten_Presshärten_verrauscht_normiert.xlsx\")\n",
    "\n",
    "# Ausgabe gewählte Zufallszahlen\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Daten erkunden - TODO\n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code für einen ersten von dir gewählten Schritt zum Daten erkunden\n",
    "- Anregungen und Hilfe im Cheat_Sheet_Daten_erkunden (OPAL)\n",
    "- Ausführen des 2. Code-Blocks (markieren und \"Run\" drücken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Code-Block\n",
    "\n",
    "# 1. Schritt Daten erkunden\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Daten erkunden - TODO\n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code für einen zweiten von dir gewählten Schritt zum Daten erkunden\n",
    "- Anregungen und Hilfe im Cheat_Sheet_Daten_erkunden (OPAL)\n",
    "- Ausführen des 3. Code-Blocks (markieren und \"Run\" drücken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Code-Block\n",
    "\n",
    "# 2. Schritt Daten erkunden\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Daten vorbereiten - Aufteilen der Daten in Trainings- und Testdaten\n",
    "\n",
    "Der Datensatz wird in einen Trainingsdatensatz, einen Validationsdatensatz und einen Testdatensatz aufgeteilt, übliche Werte sind:\n",
    "- 60% Training\n",
    "- 25% Validierung\n",
    "- 15% Testen\n",
    "\n",
    "Mit dem Trainingsdatensatz werden die Regressionsbäume trainiert, mit den Validierungsdaten werden sie gegeneinander verglichen und ein Vorzugsmodell ausgewählt. Mit den Testdaten wird das Vorzugsmodell getestet.\n",
    "\n",
    "TODO:\n",
    "- Wähle für train_size einen Wert zwischen 0.4 und 0.6 (4. Code-Block - Zeile 4)\n",
    "- Wähle für valid_size einen Wert zwischen 0.2 und 0.3 (4. Code-Block - Zeile 5)\n",
    "- Ausführen des 4. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Größe der Datensätze\n",
    "- Ersten 3 Zeilen von X und von y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Code-Block\n",
    "\n",
    "# Verhältnis Trainings- und Testdaten\n",
    "train_size = TODO\n",
    "valid_size = TODO\n",
    "test_size = 1 - train_size - valid_size\n",
    "\n",
    "# Teile Datensatz in Trainings- und Testdatensatz auf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_, X_test, y_, y_test = train_test_split(\n",
    "    df.drop(columns=[\"Bauteilhärte\"]),\n",
    "    df[\"Bauteilhärte\"],\n",
    "    test_size=(test_size),\n",
    "    random_state=my_seed,\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_, y_, test_size=(valid_size), random_state=my_seed\n",
    ")\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Validationsdaten: \\t\" + str(len(y_valid)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\\t\" + str(len(y_test)) + \" / \" + str(len(df)))\n",
    "print(\"\\nX: \" + str(list(X_train)))\n",
    "print(\"y: [Bauteilhärte]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Mögliche Hyperparameter anzeigen\n",
    "\n",
    "Vor der Erstellung eines Modells lassen wir uns zunächst alle einstellbaren Hyperparameter anzeigen.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 5. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Mögliche Hyperparameter für die Erstellung des Regressionsbaumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Code-Block\n",
    "\n",
    "# Ausgabe möglicher Hyperparameter\n",
    "from sklearn import tree\n",
    "\n",
    "tree.DecisionTreeRegressor().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - 4 Modelle erstellen und trainieren\n",
    "\n",
    "Es werden 4 Modelle mit unterschiedlichen Hyperparametern aufgestellt um deren Genauigkeit gegeneinander zu vergleichen, für das Aufstellen von Regressionsbäumen sind folgende Hyperparameter üblich:\n",
    "\n",
    "- max_depth (maximale Tiefe des Baumes)\n",
    "- max_leaf_nodes (maximale Anzahl an Blättern)\n",
    "- min_smaples_leaf (minimale Anzahl an Datenpunkten pro Blatt)\n",
    "\n",
    "TODO:\n",
    "- Setze die von dir gewählten Hyperparameter mit ihren Werten in die Klammer hinter dem jeweiligen Modell ein (6. Code-Block - Zeile 4-7)\n",
    "- Varriere mindestens 2 Hyperparameter in den 4 Modellen (z.B: max_depth und max_leaf_nodes)\n",
    "- Natürlich können auch anderen von dir gewählte Hyperparameter ausrobiert werden.\n",
    "- Setze immer den Hyperparameter random_state=my_seed ein (6. Code-Block - Zeile 4-7)\n",
    "- z.B. regr_tree_1 = tree.DecisionTreeRegressor(random_state=my_seed, max_depth=5, max_leaf_nodes=10)\n",
    "- Ausführen des 6. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Knotenanzahl der trainierten Entscheidungsbäume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Code-Block\n",
    "\n",
    "# Erstellen der 4 Modelle\n",
    "regr_tree_1 = tree.DecisionTreeRegressor(random_state=TODO, TODO, TODO)\n",
    "regr_tree_2 = tree.DecisionTreeRegressor(random_state=TODO, TODO, TODO)\n",
    "regr_tree_3 = tree.DecisionTreeRegressor(random_state=TODO, TODO, TODO)\n",
    "regr_tree_4 = tree.DecisionTreeRegressor(random_state=TODO, TODO, TODO)\n",
    "\n",
    "# Trainiere die 4 Modelle\n",
    "regr_tree_1 = regr_tree_1.fit(X_train, y_train)\n",
    "regr_tree_2 = regr_tree_2.fit(X_train, y_train)\n",
    "regr_tree_3 = regr_tree_3.fit(X_train, y_train)\n",
    "regr_tree_4 = regr_tree_4.fit(X_train, y_train)\n",
    "\n",
    "# Ausgabe Knotenanzahl der trainierten 4 Modelle\n",
    "print(\"\\nKnotenanzahl Regressionsbaum 1: \\t\" + str(regr_tree_1.tree_.node_count))\n",
    "print(\"Knotenanzahl Regressionsbaum 2: \\t\" + str(regr_tree_2.tree_.node_count))\n",
    "print(\"Knotenanzahl Regressionsbaum 3: \\t\" + str(regr_tree_3.tree_.node_count))\n",
    "print(\"Knotenanzahl Regressionsbaum 4: \\t\" + str(regr_tree_4.tree_.node_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modelle bilden - Anzeigen der Regressionsbäume\n",
    "\n",
    "Ausgabe eines trainierten Regressionsbaumes. Zeige dir nacheinander alle 4 Regressionsbäume an.\n",
    "\n",
    "TODO:\n",
    "- Wähle für tree_now den anzuzeigenden Regressionsbaum (7. Code-Block - Zeile 4)\n",
    "- z.B. tree_now = regr_tree_1\n",
    "- Ausführen des 7. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Struktur der trainierten Entscheidungsbaumes\n",
    "\n",
    "Die Berechnung der Ausgabe benötigt ein paar Sekunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Code-Block\n",
    "\n",
    "# Ausgabe des Modells\n",
    "tree_now = TODO\n",
    "\n",
    "# Ausgabe des trainierten Entscheidungsbaumes\n",
    "plt.figure(figsize=(14, 14))\n",
    "tree.plot_tree(tree_now, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Modelle bilden - Bewertung des Trainings - Bewertung des Trainings - Graph (Y/Y_pred)\n",
    "\n",
    "Um das Training der 4 Modelle zu bewerten schauen wir uns die Graphen (y/Y_pred) an.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 8. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- 4 Graphen: Bauteilhärte über vorhergesagter Bauteilhärte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Code-Block\n",
    "\n",
    "# Ausgabe Graphen\n",
    "min_train, max_train = y_train.min(), y_train.max()\n",
    "plt.figure(figsize=(16, 12))\n",
    "trees = [regr_tree_1, regr_tree_2, regr_tree_3, regr_tree_4]\n",
    "for i, tr in enumerate(trees):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.plot(y_train, np.squeeze(tr.predict(X_train)), \"o\", alpha=0.4)\n",
    "    plt.plot([min_train, max_train], [min_train, max_train], \"--\", c=(0, 0, 0))\n",
    "    plt.xlabel(\"reale Bauteilhärte\")\n",
    "    plt.ylabel(\"vorhergesagte Bauteilhärte\")\n",
    "    plt.title(\"Regressionsbaum \" + str(i + 1) + \" - Trainingsdaten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Modelle bilden - Bewertung des Trainings - MAE\n",
    "\n",
    "Wir berechnen den MAE jedes Modells auf den Trainingsdaten.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 9. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- MAE auf Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Code-Block\n",
    "\n",
    "# Berechne Baumnummer, Anzahl Knoten, maximale Tiefe, RMSE & MAE auf Trainingsdaten\n",
    "from sklearn.metrics import mean_absolute_error as mae \n",
    "\n",
    "results_ = [[], [], [], []]\n",
    "trees = [regr_tree_1, regr_tree_2, regr_tree_3, regr_tree_4]\n",
    "for i, tr in enumerate(trees):\n",
    "    results_[0].append(i + 1)\n",
    "    results_[1].append(tr.tree_.node_count)\n",
    "    results_[2].append(tr.tree_.max_depth)\n",
    "    results_[3].append(mae(y_test, tr.predict(X_test)))\n",
    "\n",
    "# Ausgabe\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"Baum #\": results_[0],\n",
    "        \"Anzahl Knoten\": results_[1],\n",
    "        \"maximale Tiefe\": results_[2],\n",
    "        \"MAE (Train)\": results_[3],\n",
    "    }\n",
    ")\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Validieren der Modelle - Vergleich der Modelle untereinander - Graph (Y/Y_pred)\n",
    "\n",
    "Um die verschiedenen Modelle (bzw. die verschiedenen Hyperparameter) zu vergleichen (die Modelle zu validieren) betrachten wir die Graphen (y/Y_pred).\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 10. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- 4 Graphen: Bauteilhärte über vorhergesagter Bauteilhärte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Code-Block\n",
    "\n",
    "# Ausgabe Graphen\n",
    "min_valid, max_valid = y_valid.min(), y_valid.max()\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "for i, tr in enumerate(trees):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.plot(y_valid, np.squeeze(tr.predict(X_valid)), \"o\", alpha=0.4)\n",
    "    plt.plot([min_valid, max_valid], [min_valid, max_valid], \"--\", c=(0, 0, 0))\n",
    "    plt.xlabel(\"reale Bauteilhärte\")\n",
    "    plt.ylabel(\"vorhergesagte Bauteilhärte\")\n",
    "    plt.title(\"Regressionsbaum \" + str(i + 1) + \" - Validierungsdaten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Validieren der Modelle - Vergleich der Modelle untereinander - MAE\n",
    "\n",
    "Um die verschiedenen Modelle (bzw. die verschiedenen Hyperparameter) zu vergleichen/validieren berechnen wir den MAE.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 11. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Ergebnis-Tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Code-Block\n",
    "\n",
    "# Berechne MAE auf Validierungsdaten\n",
    "results_ = []\n",
    "for i, tr in enumerate(trees):\n",
    "    results_.append(mae(y_valid, tr.predict(X_valid)))\n",
    "\n",
    "# Ausgabe\n",
    "results[\"MAE (Valid)\"] = results_\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Validieren der Modelle - Auswahl eines Vorzugsmodells\n",
    "\n",
    "TODO:\n",
    "- Wähle anhand der Validierungsfehler und -Graphen das beste Modell aus (12. Code-Block - Zeile 4)\n",
    "- z.B. best_model = regr_tree_2\n",
    "- Ausführen des 12. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Struktur Vorzugsmodell\n",
    "\n",
    "Die Berechnung der Ausgabe benötigt ein paar Sekunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Code-Block\n",
    "\n",
    "# Auswahl Vorzugsmodell\n",
    "best_model = TODO\n",
    "\n",
    "# Ausgabe Vorzugsmodell\n",
    "plt.figure(figsize=(16, 8))\n",
    "tree.plot_tree(best_model, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Bewertung des Vorzugsmodells - Graph (y/y_pred)\n",
    "\n",
    "Um das Vorzugsmodell zu bewerten betrachten wir den Graphen (y/y_pred). Hierzu benötigen wir y und y_pred.\n",
    "\n",
    "TODO:\n",
    "- Setze für y y_test ein (13. Code-Block - Zeile 4)\n",
    "- Setze in die .predict-Funktion X_test ein (13. Code-Block - Zeile 5)\n",
    "- Die .predict-Funktion berechnet für alle X-Werte ein y_pred\n",
    "- Ausführen des 13. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Bauteilhärte über vorhergesagter Bauteilhärte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Code-Block\n",
    "\n",
    "# Berechnung der Genauigkeit mit y und y_pred\n",
    "y = TODO\n",
    "y_pred = best_model.predict(TODO)\n",
    "\n",
    "# Ausgabe Graph\n",
    "min_test, max_test = y_test.min(), y_test.max()\n",
    "plt.figure(figsize=(9, 8))\n",
    "plt.plot(y, np.squeeze(y_pred), \"o\", alpha=0.4)\n",
    "plt.plot([min_test, max_test], [min_test, max_test], \"--\", c=(0, 0, 0))\n",
    "plt.xlabel(\"reale Bauteilhärte\")\n",
    "plt.ylabel(\"vorhergesagte Bauteilhärte\")\n",
    "plt.title(\"Vorzugsmodell - Testdaten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Modell testen & anwenden - Bewertung der Vorzugsmodells - MAE\n",
    "\n",
    "Um das Vorzugsmodell zu bewerten berechnen wir den MAE.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 14. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Ergebnis-Tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Code-Block\n",
    "\n",
    "# Berechne RMSE & MAE auf Testdaten\n",
    "mae_test = mae(y_test, best_model.predict(X_test))\n",
    "\n",
    "# Ausgabe\n",
    "print(\"\\nVorzugsmodell:\\nMAE (Test): \\t\" + str(\"%.3f\" % mae_test))\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Über den Verlauf des Prozesses kann der Fehler nicht geringer werden:\n",
    "\n",
    "- Ein Modell mit einem MAE (Train) von 10 hat einen MAE (Valid) von 10 oder mehr.\n",
    "- Ein Modell mit einem MAE (Valdid) von 10 hat einen MAE (Test) von 10 oder mehr.\n",
    "\n",
    "### MAE (Train) <= MAE (Valid) <= MAE (Test)\n",
    "\n",
    "Bei einem guten Modell gilt: MAE (Train) ~ MAE (Valid) ~ MAE (Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Erkenntnisse aus dem Modell/Nutzen\n",
    "\n",
    "Ausgabe der Wichtigkeit der einzelnen Input-Variablen.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 15. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Graph: Einfluss der Input-Variablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Code-Block\n",
    "\n",
    "# Ausgabe Graph Einfluss der Input-Variablen\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(list(X_train), best_model.feature_importances_, align=\"center\")\n",
    "plt.title(\"Einfluss der Input-Variablen auf die Bauteilhärte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualisierung: MAE über der Baumtiefe und der Anzahl der Blätter \n",
    "\n",
    "TODO:\n",
    "- Ausführen des 16. Code-Blocks (markieren und \"Run\" drücken)\n",
    "\n",
    "AUSGABE:\n",
    "- Interaktive Darstellung der Genauigkeit by varrierenden Hyperparametern\n",
    "- Doppelt ausführen damit die interaktive Grafik angezeigt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Code-Block\n",
    "\n",
    "# Berechne Grid\n",
    "leafs = np.arange(15, 300, 20)\n",
    "depths = np.arange(4, 19, 1)\n",
    "X, Y = np.meshgrid(leafs, depths)\n",
    "\n",
    "# Berechne Genauigkeit je Gridpunkt\n",
    "z = []\n",
    "for i in range(225):\n",
    "\n",
    "    # Trainiere Modell & Berechne Vorhersage\n",
    "    regression_tree = tree.DecisionTreeRegressor(\n",
    "        random_state=my_seed,\n",
    "        max_leaf_nodes=int(X.ravel()[i]),\n",
    "        max_depth=int(Y.ravel()[i]),\n",
    "    )\n",
    "    regression_tree = regression_tree.fit(X_train, y_train)\n",
    "    results_ = pd.DataFrame(y_test)\n",
    "\n",
    "    # Berechne MAE\n",
    "    mae_test = mae(y_test, regression_tree.predict(X_test))\n",
    "    z.append(mae_test)\n",
    "Z = np.asarray(z).reshape(15, 15)\n",
    "\n",
    "# Ausgabe\n",
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "plt.title(\n",
    "    \"MAE abhängig von der maximalen Anzahl an Blättern und der maximalen Tiefe des Baumes\"\n",
    ")\n",
    "plt.xlabel(\"maximale Anzahl Blätter\")\n",
    "plt.ylabel(\"maximale Tiefe des Baumes\")\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.viridis, alpha=0.5, antialiased=False)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.view_init(30, 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verständnisfragen:\n",
    "\n",
    "1. Welchen MAE erreicht dein bestes Modell (auf den Testdaten)? Wie viele Blätter und welche Tiefe besitzt das Modell?\n",
    "2. Ist das Verfahren (Regressionsbaum) grundsätzlich besser oder schlechter als die Lineare Regression für das Beispiel Presshärten geeignet (siehe Ausgabe Punkt 5.1)?\n",
    "3. Wieviele Blätter und welche Tiefe hat der genaueste Regressionsbaum (zu Ausgabe Punkt 7.)? Bonusfrage\n",
    "4. Es wurden 3 verschiedene MAE berechnet (Trainings-, Validierungs- und Testdaten). Welche Schlussfolgerungen kannst du aus den jeweiligen MAEs ziehen? Bonusfrage"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
