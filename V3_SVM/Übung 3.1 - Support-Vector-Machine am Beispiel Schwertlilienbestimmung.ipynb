{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 3.1 - Support-Vector-Machine am Beispiel Schwertlilienbestimmung\n",
    "VO Maschinelles Lernen in der Produktion, WS2020/21, Moritz von Unold, Richard Lux, Felix Soest\n",
    "\n",
    "#### In diesem Notebook wird das Verfahren Support-Vector-Machine (SVM) anhand des Anwendungsbeispiels Schwertlilienbestimmung geübt.\n",
    "\n",
    "Im Datensatz der Schwertlilien werden drei verschiedene Lilienarten anhand 4 Eigenschaften (Breite und Länge der Kelchblätter, Breite und Länge der Kronblätter) klassifiziert. Es soll eine Support-Vector-Machine (SVM) erstellt werden welche bei gegebenen Breiten und Längen der Kelch- und Kronblätter die Art der Lilie (iris-setosa, iris-virginica oder iris-versicolor) bestimmen kann. \n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Code-Block\n",
    "\n",
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen\n",
    "\n",
    "TODO:\n",
    "- Wähle eine Zahl für die Generierung deiner spezifischen Zufallszahlen  (1. Code-Block - Zeile 4)\n",
    "\n",
    "AUSGABE:\n",
    "- Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Code-Block\n",
    "\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Lade Datensatz und Ausgabe Zufallszahl\n",
    "df = pd.read_excel(\"Daten_Schwertlilien.xlsx\")\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Code-Block\n",
    "\n",
    "# Daten erkunden\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, hue=\"Lilienart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Daten vorbereiten - Aufteilen in Trainings-, Validations- und Testdaten\n",
    "\n",
    "TODO:\n",
    "- Wähle Werte für train_size und für valid_size (3. Code-Block - Zeile 4-5)\n",
    "\n",
    "AUSGABE:\n",
    "- Größe der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Code-Block\n",
    "\n",
    "# Verhältnis Trainings- und Testdaten\n",
    "train_size = TODO\n",
    "valid_size = TODO\n",
    "\n",
    "# Teile Datensatz in Trainings- und Testdatensatz auf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_, X_test, y_, y_test = train_test_split(\n",
    "    df.drop(columns=[\"Lilienart\"]),\n",
    "    df[\"Lilienart\"],\n",
    "    test_size=(1 - train_size - valid_size),\n",
    "    random_state=my_seed,\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_, y_, test_size=(valid_size), random_state=my_seed\n",
    ")\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Validationsdaten: \\t\" + str(len(y_valid)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\\t\" + str(len(y_test)) + \" / \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Mögliche Hyperparameter anzeigen\n",
    "\n",
    "Vor der Erstellung eines Modells lassen wir uns zunächst alle einstellbaren Hyperparameter anzeigen.\n",
    "\n",
    "TODO:\n",
    "- Schreibe die Code-Zeilen um das Modell zu importieren (Hilfestellung im Cheat-Sheet Modelle bilden)\n",
    "- Schreibe die Code-Zeile um die möglichen Hyperparameter anzuzeigen (Hilfestellung im Cheat-Sheet Modelle bilden)\n",
    "\n",
    "AUSGABE:\n",
    "- Mögliche Hyperparameter für die Erstellung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Code-Block\n",
    "from sklearn import svm\n",
    "# Importieren des Modells\n",
    "TODO\n",
    "\n",
    "# Ausgabe möglicher Hyperparameter\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Optimale Hyperparameter mittels Gittersuche bestimmen\n",
    "\n",
    "Für die SVM mit __Linearem Kernel__ werden in diesem Notebook 3 Hyperparameter eingestellt:\n",
    "- C: Der Strafterm C.\n",
    "- kernel: Der Kernel.\n",
    "- random_state: Die Zufallszahlen zur Erzeugung des Modells.\n",
    "\n",
    "Um den optimalen Wert für C zu finden wird eine sog. __Gittersuche__ durchgeführt:\n",
    "- Bestimme mehrere Werte für C\n",
    "- Für jeden dieser Werte wird:\n",
    "    - Ein Modell erstellt \n",
    "    - Ein Modell trainiert\n",
    "    - Die Genauigkeit auf den Validationsdaten berechnet\n",
    "- Der C-Wert welcher die höchste Genauigkeit zeigt wird für das Vorzugsmodell verwendet\n",
    "\n",
    "TODO:\n",
    "- Wähle die C-Werte für die Gittersuche (6. Code-Block - Zeile 4)\n",
    "- Es gibt 3 Möglichkeiten die Werte einzutragen:\n",
    "    - Möglichkeit 1: Manuelles Eintragen in eine Liste: z.B. Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    - Möglichkeit 2: Erzeugen einer Liste mit np.linspace(): z.B. Cs = np.linspace(von, bis, Anzahl an Werten)\n",
    "    - Möglichkeit 3: Erzeugen einer Liste mit np.logspace(): z.B. Cs = np.logspace(exp. von, exp. bis, Anzahl an Werten)\n",
    "\n",
    "AUSGABE:\n",
    "- optimale Hyperparameter\n",
    "- Graph: Genauigkeit über Hyperparametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Code-Block\n",
    "\n",
    "# Werte für die Gittersuche\n",
    "C_values = TODO\n",
    "\n",
    "# Berechne Genauigkeit auf Validationsdaten für alle möglichen Kombinationen\n",
    "accuracy = []\n",
    "for C in C_values:\n",
    "    # Erstelle, trainiere und validiere Modell\n",
    "    clf = svm.SVC(kernel=\"linear\", random_state=my_seed, C=C)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Berechne Gnenauigkeit auf Validierungsdaten\n",
    "    accuracy.append(clf.score(X_valid, y_valid))\n",
    "\n",
    "# Ausgabe Graphen\n",
    "idx_min = accuracy.index(max(accuracy))\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(C_values, accuracy, \"o--\")\n",
    "plt.xlabel(\"C-Wert\")\n",
    "plt.ylabel(\"Genauigkeit\")\n",
    "plt.title(\"Genauigkeit des Modells auf Validationsdaten\")\n",
    "plt.xscale(\"log\")\n",
    "plt.plot(C_values[idx_min], accuracy[idx_min], \"ro\")\n",
    "\n",
    "# Ausgabe bester alpha-Wert\n",
    "print(\"\\nAusprobierte C-Werte:\\n\\t\" + str(C_values))\n",
    "print(\n",
    "    \"\\nOptimale Hyperparameter dieser Gittersuche (Genauigkeit: \"\n",
    "    + str(\"%.3f\" % max(accuracy))\n",
    "    + \"):\"\n",
    ")\n",
    "print(\"\\tC-Wert:\\t\" + str(\"%.5f\" % C_values[accuracy.index(max(accuracy))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modell bilden - Vorzugs-Modell erstellen und trainieren\n",
    "\n",
    "Erstelle das Modell mit den optimalen Hyperparametern (aus der Gittersuche) und trainiere dieses mit den Trainingsdaten.\n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code für die Modell-Erstellung (7. Code-Block - Zeile 4) (Hilfestellung im Cheat-Sheet Modelle bilden)\n",
    "    - Hyperparameter kernel='linear', random_state=my_seed und C=TODO\n",
    "- Schreibe den Code für das Training des Modells (7. Code-Block - Zeile 7) (Hilfestellung im Cheat-Sheet Modelle bilden)\n",
    "- __Verwende den Namen clf_best für das Modell__\n",
    "\n",
    "AUSGABE:\n",
    "- Genauigkeit auf den Trainingsdaten & Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Code-Block\n",
    "\n",
    "# Erstellen des Modells\n",
    "TODO\n",
    "\n",
    "# Trainiere das Modell\n",
    "TODO\n",
    "\n",
    "# Ausgabe Genauigkeit auf Trainingsdaten\n",
    "print(\n",
    "    \"\\nGenauigkeit auf den Trainingsdaten:\\t\"\n",
    "    + str(\"%.5f\" % clf_best.score(X_train, y_train))\n",
    ")\n",
    "print(\n",
    "    \"Genauigkeit auf den Validierungsdaten:\\t\"\n",
    "    + str(\"%.5f\" % clf_best.score(X_valid, y_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Genauigkeit auf Testdaten und Konfusionsmatrix\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird dieses auf den Testdaten getestet sowie die Konfusionsmatrix angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Code-Block\n",
    "\n",
    "# Berechne Genauigkeit auf Testdaten\n",
    "accuracy_test = clf_best.score(X_test, y_test)\n",
    "\n",
    "# Ausgabe Genauigkeit auf Testdatenz\n",
    "print(\n",
    "    \"\\nGenauigkeit auf den Testdaten: \"\n",
    "    + str(\"%.3f\" % clf_best.score(X_test, y_test))\n",
    ")\n",
    "\n",
    "# Importieren der Funktion: Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Erzeuge Matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = y_test.unique()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Konfusionsmatrix auf Testdaten\")\n",
    "plt.ylabel(\"Vorhersage\")\n",
    "plt.xlabel(\"Realer Wert\")\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.margins(0, 0)\n",
    "fmt = \"d\"\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verständnisfragen:\n",
    "\n",
    "1. Welche Kernel stehen für die SVM zur Auswahl? Welcher Kernel wurde hier verwendet und warum? (Siehe Dokumentation, Link unter 4.1)\n",
    "2. Welche Nachteile hat es bei der Gittersuche zu viele Werte auszuprobieren?\n",
    "3. Welche Nachteile hat es bei der Gittersuche zu wenig Werte auszuprobieren?\n",
    "4. Bringe die 4. Schritte in die richtige Reihenfolge:\n",
    "    - Modell trainieren\n",
    "    - Modell testen\n",
    "    - Modell importieren\n",
    "    - Modell erstellen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
