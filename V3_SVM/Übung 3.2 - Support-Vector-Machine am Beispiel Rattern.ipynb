{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 3.2 - Support-Vector-Machine am Beispiel Rattern\n",
    "VO Maschinelles Lernen in der Produktion, WS2020/21, Moritz von Unold, Richard Lux, Felix Soest\n",
    "\n",
    "#### In diesem Notebook wird das Verfahren Support-Vector-Machine (SVM) anhand des Anwendungsbeispiels Rattern geübt .\n",
    "\n",
    "Bei der Fertigung von Bauteilen treten manchmal störende Schwingungen auf, sog. Rattern. Dieses schädigt die Werkzeuge und führt zu einer niedrigeren Bauteilqualität.\n",
    "\n",
    "Im Datensatz \"Rattern\" werden die Drehzahl der Spindel und die Tiefe des Schnitts einer CNC-Fräse gemessen. Es soll eine Support-Vector-Machine (SVM) erstellt werden welche vorhersagen kann bei welcher Kombination aus Drehzahl und Tiefe das sog. Rattern auftritt. \n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Code-Block\n",
    "\n",
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren\n",
    "\n",
    "TODO:\n",
    "- Wähle eine Zahl für die Generierung deiner spezifischen Zufallszahlen  (1. Code-Block - Zeile 4)\n",
    "\n",
    "AUSGABE:\n",
    "- Gewählte Zufallszahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Code-Block\n",
    "\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Lade Datensatz und Ausgabe Zufallszahl\n",
    "df_train = pd.read_csv(\"Trainingsdaten_Rattern.csv\")\n",
    "df_test = pd.read_csv(\"Testdaten_Rattern.csv\")\n",
    "df = df_train.append(df_test)\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Code-Block\n",
    "\n",
    "# Datensatz anzeigen\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Code-Block\n",
    "\n",
    "# Datensatz beschreiben\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Code-Block\n",
    "\n",
    "# Zeige Klassenzugehörigkeit an\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "surf = plt.scatter(\n",
    "    df[\"Drehzahl Spindel\"],\n",
    "    df[\"Tiefe des Schnitts\"],\n",
    "    c=df[\"Rattern\"],\n",
    "    cmap=plt.cm.coolwarm,\n",
    "    s=150,\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "plt.colorbar(surf)\n",
    "plt.xlim(7750, 16250)\n",
    "plt.ylim(0, 0.023)\n",
    "plt.xlabel(\"Drehzahl Spindel\")\n",
    "plt.ylabel(\"Tiefe des Schnitts\")\n",
    "plt.title(\"Effekt des Ratterns über Schnitttiefe und Spindeldrehzahl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Daten vorbereiten - Aufteilen in Trainings- und Validationsdaten\n",
    "\n",
    "Es wurden die Datensätze Trainingsdaten und Testdaten getrennt importiert, die Validierungsdaten werden mittels Cross-Validation aus den Trainingsdaten gewählt.\n",
    "\n",
    "Optional können die Input-Parameter (Schnitttiefe und Spindeldrehzahl) normiert werden (Abbildung auf Bereich 0 bis 1).\n",
    "\n",
    "TODO:\n",
    "- __optionale Normierung:__ Wenn du die Daten normieren möchtest entferne das erste Zeichen (#) in den Zeilen 15 und 16 (5. Code-Block - Zeile 15-16)\n",
    "\n",
    "AUSGABE:\n",
    "- Größe der Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Code-Block\n",
    "\n",
    "# Teile Datensatz in X und y auf\n",
    "X_train_, y_train = (\n",
    "    df_train[[\"Drehzahl Spindel\", \"Tiefe des Schnitts\"]],\n",
    "    df_train[\"Rattern\"],\n",
    ")\n",
    "X_test_, y_test = (\n",
    "    df_test[[\"Drehzahl Spindel\", \"Tiefe des Schnitts\"]],\n",
    "    df_test[\"Rattern\"],\n",
    ")\n",
    "\n",
    "# Normiere Input-Parameter (optionales TODO)\n",
    "X_train, X_test = X_train_.copy(deep=True), X_test_.copy(deep=True)\n",
    "#X_train = (X_train - X_train_.min()) / (X_train_.max() - X_train_.min())\n",
    "#X_test = (X_test - X_train_.min()) / (X_train_.max() - X_train_.min())\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\n",
    "    \"\\nAnzahl Trainingsdaten: \\t\\t\"\n",
    "    + str(len(y_train))\n",
    "    + \" / \"\n",
    "    + str(len(df_train) + len(df_test))\n",
    ")\n",
    "print(\n",
    "    \"Anzahl Testdaten: \\t\\t\"\n",
    "    + str(len(y_test))\n",
    "    + \" / \"\n",
    "    + str(len(df_train) + len(df_test))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Mögliche Hyperparameter anzeigen\n",
    "\n",
    "Vor der Erstellung eines Modells lassen wir uns zunächst alle einstellbaren Hyperparameter anzeigen.\n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code um das Modell aus der Bibliothek zu importieren (Cheat Sheet Modelle bilden)\n",
    "- Schreibe den Code um die möglichen Hyperparameter angezeigt zu bekommen (Cheat Sheet Modelle bilden)\n",
    "\n",
    "AUSGABE:\n",
    "- Mögliche Hyperparameter für die Erstellung des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Code-Block\n",
    "\n",
    "# Importiere das Modell aus der Bibliothek sklearn\n",
    "TODO\n",
    "\n",
    "# Ausgabe möglicher Hyperparameter\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Optimale Hyperparameter mittels Gittersuche bestimmen\n",
    "\n",
    "Für die __SVM mit rbf-Kernel__ werden in diesem Notebook __4 Hyperparameter__ eingestellt:\n",
    "- kernel: Der Kernel.\n",
    "- random_state: Die Zufallszahlen zur Erzeugung des Modells.\n",
    "- C: Der Strafterm C.\n",
    "- gamma: Der Kernel Koeffizient gamma.\n",
    "\n",
    "Um die optimalen Werte für die Hyperparameter C und gamma zu finden wird eine __Gittersuche__ durchgeführt:\n",
    "- Bestimme zu probierende Werte für C, gamma\n",
    "- Für diese Werte wird für alle Kombinationen:\n",
    "    - Ein Modell erstellt \n",
    "    - Ein Modell trainiert\n",
    "    - Die Genauigkeit auf den Validationsdaten berechnet\n",
    "- Die Hyperparameter mit der höchsten Genauigkeit werden für das Vorzugsmodell verwendet\n",
    "\n",
    "TODO:\n",
    "- Schreibe die C-Werte für die Gittersuche in eine Liste hinter 'C': (7. Code-Block - Zeile 9)\n",
    "- Schreibe die gamma-Werte für die Gittersuche in eine Liste hinter 'gamma': (7. Code-Block - Zeile 9)\n",
    "- Es gibt 3 Möglichkeiten die Werte einzutragen:\n",
    "    - Möglichkeit 1: Manuelles Eintragen in eine Liste: Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    - Möglichkeit 2: Erzeugen einer Liste mit np.linspace(): Cs = np.linspace(von, bis, Anzahl an Werten)\n",
    "    - Möglichkeit 3: Erzeugen einer Liste mit np.logspace(): Cs = np.logspace(exp. von, exp. bis, Anzahl an Werten)\n",
    "\n",
    "AUSGABE:\n",
    "- optimale Hyperparameter\n",
    "- Graph: Genauigkeit über Hyperparametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Code-Block\n",
    "\n",
    "# Werte für die Gittersuche/Hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start_timer = time.monotonic()\n",
    "hyper_parameters = [\n",
    "    {\"kernel\": [\"rbf\"], \"C\": TODO, \"gamma\": TODO, \"random_state\": [my_seed]}\n",
    "]\n",
    "\n",
    "# Gittersuche: Berechne Genauigkeit auf Validationsdaten für alle möglichen Kombinationen\n",
    "clf = svm.SVC()\n",
    "gridSearch = GridSearchCV(clf, hyper_parameters, return_train_score=True, cv=5)\n",
    "gridSearch = gridSearch.fit(X_train, y_train)\n",
    "print(\n",
    "    \"\\nDie Gittersuche (\"\n",
    "    + str(len(pd.DataFrame(gridSearch.cv_results_)))\n",
    "    + \" Kombinationen) hat \"\n",
    "    + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "    + \" Sekunden gedauert.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In der Variable GridSearch sind nun die Ergebnisse der Gittersuche gespeichert ...\n",
    "#### 1. mit GridSearch.best_estimator_ bekommen wir die besten Hyperparameter der Gittersuche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Code-Block - Beste Kombination der Hyperparameter\n",
    "gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. mit GridSearch.best_score_  bekommen wir die Genauigkeit der besten Hyperparameter der Gittersuche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Code-Block - Genauigkeit der besten Hyperparameter\n",
    "gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. mit GridSearch.cv_results_ bekommen wir die Ergebnis-Tabelle der Gittersuche (hier: besten 5 Hyperparameter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Code-Block - Top 5 Hyperparameter\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\n",
    "    \"mean_test_score\", ascending=False\n",
    ").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Anzeigen einer sog. Heatmap der Hyperparameter C und gamma (nur bei 2 variierenden Hyperparametern möglich):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 11. Code-Block\n",
    "results = pd.DataFrame(gridSearch.cv_results_)\n",
    "xx = results[\"param_C\"].unique()\n",
    "yy = results[\"param_gamma\"].unique()\n",
    "zz = np.asarray(results[\"mean_test_score\"]).reshape(len(xx), len(yy)).T\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\n",
    "    \"GITTERSUCHE: Genauigkeit (Validationsdaten) über den Hyperparametern C und gamma\"\n",
    ")\n",
    "surf = plt.contourf(xx, yy, zz, cmap=plt.cm.coolwarm_r)\n",
    "fig.colorbar(surf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modell bilden - Vorzugs-Modell erstellen und trainieren\n",
    "\n",
    "Erstelle das Modell mit den optimalen Hyperparametern und trainiere dieses mit den Trainingsdaten.\n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code für die Modell-Erstellung (12. Code-Block - Zeile 4) (Cheat Sheet Modelle bilden)\n",
    "- Schreibe den Code für das Training des Modells (12. Code-Block - Zeile 7) (Cheat Sheet Modelle bilden)\n",
    "- __Verwende den Namen clf_best für das Modell__\n",
    "\n",
    "AUSGABE:\n",
    "- Genauigkeit auf den Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Code-Block\n",
    "\n",
    "# Erstellen des Modells\n",
    "TODO\n",
    "\n",
    "# Trainiere das Modell\n",
    "TODO\n",
    "\n",
    "# Ausgabe Genauigkeit auf Trainingsdaten\n",
    "print(\n",
    "    \"\\nGenauigkeit auf den Trainingsdaten:\\t\"\n",
    "    + str(\"%.4f\" % clf_best.score(X_train, y_train))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Genauigkeit auf Testdaten und Konfusionsmatrix\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird dieses auf den Testdaten getestet und die Konfusionsmatrix ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Code-Block\n",
    "\n",
    "# Berechne Genauigkeit auf Testdaten\n",
    "accuracy_test = clf_best.score(X_test, y_test)\n",
    "\n",
    "# Ausgabe Genauigkeit auf Testdatenz\n",
    "print(\"\\nGenauigkeit auf den Testdaten: \" + str(\"%.4f\" % accuracy_test))\n",
    "\n",
    "# Importieren der Funktion: Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Erzeuge Matrix\n",
    "y_pred = clf_best.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = y_test.unique()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Konfusionsmatrix auf Testdaten\")\n",
    "plt.ylabel(\"Vorhersage\")\n",
    "plt.xlabel(\"Realer Wert\")\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "plt.margins(0, 0)\n",
    "fmt = \"d\"\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Modell testen & anwenden - Modell visualisieren\n",
    "\n",
    "Da das Modell nur 2 Input-Parameter benötigt können wir alle möglichen Modell-Vorhersagen grafisch visualisieren.\n",
    "\n",
    "TODO:\n",
    "- Ausführen des 14. Code-Blocks\n",
    "\n",
    "AUSGABE:\n",
    "- Grafische Visualisierung der Modellvorhersage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Code-Block\n",
    "\n",
    "# Erstelle Grid für Modellausgabe\n",
    "x = np.linspace(\n",
    "    X_train[\"Drehzahl Spindel\"].min(), X_train[\"Drehzahl Spindel\"].max(), 200\n",
    ")\n",
    "y = np.linspace(\n",
    "    X_train[\"Tiefe des Schnitts\"].min(), X_train[\"Tiefe des Schnitts\"].max(), 200\n",
    ")\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Berechne Modellvorhersage\n",
    "z = pd.DataFrame({\"Drehzahl Spindel\": X.ravel(), \"Tiefe des Schnitts\": Y.ravel()})\n",
    "z = clf_best.predict(z)\n",
    "\n",
    "# Ausgabe Modellvorhersage\n",
    "\n",
    "Z = np.asarray(z).reshape(200, 200)\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "plt.title(\n",
    "    \"Modellvorhersage und Datensätze (Train = Kreis, Valid = Viereck, Test = Raute)\"\n",
    ")\n",
    "plt.xlabel(\"Drehzahl Spindel\")\n",
    "plt.ylabel(\"Tiefe des Schnitts\")\n",
    "surf = plt.contourf(X, Y, Z, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar(surf)\n",
    "plt.scatter(\n",
    "    X_train[\"Drehzahl Spindel\"],\n",
    "    X_train[\"Tiefe des Schnitts\"],\n",
    "    c=y_train,\n",
    "    marker=\"o\",\n",
    "    alpha=0.3,\n",
    "    edgecolors=\"black\",\n",
    "    s=70,\n",
    ")\n",
    "plt.scatter(\n",
    "    X_test[\"Drehzahl Spindel\"],\n",
    "    X_test[\"Tiefe des Schnitts\"],\n",
    "    c=y_test,\n",
    "    marker=\"D\",\n",
    "    edgecolors=\"black\",\n",
    "    s=70,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verständnisfragen:\n",
    "\n",
    "1. Wann ist die Normierung eines Datensatzes von Vorteil? \n",
    "2. Welche Probleme treten bei nicht-normierung auf?\n",
    "2. Welcher Datensatz wird der GridSearch übergeben (Train, Test?) und wie werden die Validierungsdaten erzeugt?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
