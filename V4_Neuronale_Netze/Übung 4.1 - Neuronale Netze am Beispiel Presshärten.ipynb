{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 4.1 - Neuronale Netze am Beispiel Presshärten\n",
    "VO Maschinelles Lernen in der Produktion, WS2020/21, Moritz von Unold, Richard Lux, Felix Soest\n",
    "\n",
    "#### In diesem Notebook wird das Verfahren Neuronale Netze anhand des Anwendungsbeispiels Rattern geübt.\n",
    "\n",
    "Ziel des trainierten Neuronalen Netzes ist hier den Zusammenhang zwischen den 7 Prozess-Parametern des Presshärtens und dem daraus resultierenden Ziel-Parameter (Bauteilhärte) abzubilden.\n",
    "\n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Code-Block\n",
    "\n",
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Code-Block\n",
    "\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Lade Datensatz und Ausgabe Zufallszahl\n",
    "df = pd.read_excel(\"Daten_Presshärten.xlsx\")\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Code-Block\n",
    "\n",
    "# Letzten 5 Zeilen des Datensatzes\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Code-Block\n",
    "\n",
    "# Streudiagramm-Matrix anzeigen\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df, alpha=0.2, figsize=(16, 16), diagonal=\"hist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Daten vorbereiten - Aufteilen in Trainings- und Testdaten\n",
    "\n",
    "Der Datensatz wird in Trainings- und Testdaten aufgeteilt. Die Trainingsdaten werden automatisch im Schritt GridSearch nochmals in Trainings- und Validationsdaten aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Code-Block\n",
    "\n",
    "# Verhältnis Trainings- und Testdaten\n",
    "test_size = TODO\n",
    "\n",
    "# Teile Datensatz in Trainings- und Testdatensatz auf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[\"Bauteilhärte\"]),\n",
    "    df[\"Bauteilhärte\"],\n",
    "    test_size=test_size,\n",
    "    random_state=my_seed,\n",
    ")\n",
    "\n",
    "# Ausgabe Datensätze und Anzahl Datenpunkte\n",
    "print(\"\\nAnzahl Traingsdaten: \\t\\t\" + str(len(y_train)) + \" / \" + str(len(df)))\n",
    "print(\"Anzahl Testdaten: \\t\\t\" + str(len(y_test)) + \" / \" + str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Mögliche Hyperparameter anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Code-Block\n",
    "\n",
    "# Importieren des Modells\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "\n",
    "# Ausgabe möglicher Hyperparameter\n",
    "print(\"\\nMögliche Hyperparameter (mit Standardeinstellung) eines Neuronalen Netzes:\")\n",
    "MLPRegressor().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Optimale Hyperparameter mittels Gittersuche bestimmen\n",
    "\n",
    "Um die optimalen Hyperparameter für das Neuronale Netz zu finden wird eine __Gittersuche__ durchgeführt:\n",
    "\n",
    "TODO:\n",
    "- Schreibe die zu variierenden Hyperparameter listenweise in ein Dictionary (6. Code-Block - Zeile 5-9)\n",
    "- __Empfehlung:__ Verwende den solver lbfgs (nicht zwingend beste Möglichkeit): 'solver': ['lbfgs'], als random state deinen seed: random_state=my_seed\n",
    "- Die Struktur eines Neuronalen Netzes (Anzahl an hidden layers sowie Neuronen je hidden layer) wird wie folgt angegeben:\n",
    "    - hidden_layers_sizes = (3,) -> 1 hidden layer mit 3 Neuronen\n",
    "    - hidden_layers_sizes = (3,2) -> 2 hidden layers mit 3 und 2 Neuronen\n",
    "    - hidden_layers_sizes = (5,3,5) -> 3 hidden layers mit 5, 3 und 5 Neuronen\n",
    "    - Zur Erinnerung: Die input layer hat soviele Neuronen wir Inputparameter, die output layer hat bei der Regression 1 Neuron\n",
    "\n",
    "AUSGABE:\n",
    "- Anzahl der Kombinationen, die Dauer der Gittersuche sowie das Modell mit den besten Hyperparametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Code-Block\n",
    "\n",
    "# Werte für die Gittersuche/Hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV; import time; start_timer = time.monotonic()\n",
    "hyper_parameters = [{'hidden_layer_sizes': [TODO], \n",
    "                     TODO,\n",
    "                     TODO,\n",
    "                     TODO,\n",
    "                     'random_state': [my_seed],\n",
    "                    }]\n",
    "\n",
    "# Berechne Genauigkeit auf Validationsdaten für alle möglichen Kombinationen\n",
    "mlp = MLPRegressor()\n",
    "gridSearch = GridSearchCV(mlp, hyper_parameters, return_train_score=True, scoring='neg_mean_absolute_error', cv=5)\n",
    "gridSearch = gridSearch.fit(X_train, y_train)\n",
    "print('\\nDie Gittersuche (' + str(len(pd.DataFrame(gridSearch.cv_results_))) + ' Kombinationen) hat ' + str(\"%.1f\" % (time.monotonic()-start_timer)) + ' Sekunden gedauert, bestes Modell:')\n",
    "gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Code-Block\n",
    "\n",
    "# Ausgabe der Ergebnis-Tabelle der Gittersuche - besten 15 Modelle\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\n",
    "    \"mean_test_score\", ascending=False\n",
    ").head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modell bilden - Vorzugs-Modell erstellen und trainieren\n",
    "\n",
    "Das Modell mit den optimalen Hyperparametern wird erstell und trainiert. Danach wird der MAE auf den Trainingsdaten ausgegeben.\n",
    "\n",
    "TODO:\n",
    "- Schreibe den Code für den MAE des Modells auf den Trainingsdaten (Hilfestellung im Cheat-Sheet Modelle_testen) \n",
    "\n",
    "AUSGABE:\n",
    "- MAE auf den Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Code-Block\n",
    "\n",
    "# Erstellen des Modells - Verwenden des besten Modells aus der Gittersuche\n",
    "best_mlp = gridSearch.best_estimator_\n",
    "\n",
    "# Trainiere das Modell\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Ausgabe MAE auf Trainingsdaten\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Bewertung des Modells - MAE auf Testdaten\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird der MAE auf den Testdaten berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Code-Block\n",
    "\n",
    "# Berechne MAE auf Testdaten\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Vergleichswerte dieses Datensatzes Presshärten (MAE auf Testdaten):__\n",
    "- Lineare Regression: 10.5\n",
    "- Regressionsbaum: 10.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Modell testen & anwenden - Bewertung des Modells - y über y_pred\n",
    "\n",
    "\n",
    "TODO:\n",
    "- Schreibe die Code-Zeilen für die Darstellung des MAE (Testdaten) von y über y_pred (Hilfestellung im Cheat-Sheet Modelle testen)\n",
    "\n",
    "AUSGABE:\n",
    "- Graph: MAE über y und y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Code-Block\n",
    "\n",
    "# Ausgabe Graph: MAE über y und y_pred\n",
    "y_now = y_test  # z.B. y_test\n",
    "X_now = X_test  # z.B. X_test\n",
    "model_now = best_mlp  # z.B. nn_model_best\n",
    "min_test, max_test = y_now.min(), y_now.max()\n",
    "fig = plt.figure(figsize=(9, 8))\n",
    "plt.plot(y_now, np.squeeze(model_now.predict(X_now)), \"o\", alpha=0.4)\n",
    "plt.plot([min_test, max_test], [min_test, max_test], \"--\", c=(0, 0, 0))\n",
    "plt.xlabel(\"realer Wert\")\n",
    "plt.ylabel(\"Vorhersage\")\n",
    "plt.title(\"Modellgüte\")\n",
    "plt.xlabel(\"realer Wert\")\n",
    "plt.ylabel(\"Vorhersage\")\n",
    "plt.title(\"Modellgüte\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Modell testen & anwenden - Ausgabe der Gewichte\n",
    "\n",
    "Die Gewichtsmatrizen enthalten die Parameter zur Berechnung der Werte der einzelnen Neuronen des NN (Berechnungsvorschrift von Schicht zu Schicht). Das untrainierte Netz besteht zu Beginn aus Gewichtsmatrizen mit zufälligen Werten. Im Laufe des Trainings werden die Werte der Gewichtsmatrizen solange angepasst (Backpropagation!) bis das NN einen möglichst geringen Fehler auf den Trainingsdaten aufzeigt und somit den Zusammenhang möglichst gut abbildet. Um ein NN abzuspeichern/zu rekonstruieren muss neben den Gewichtsmatrizen nur die Struktur sowie die Aktivierungsfunktionen gespeichert werden. \n",
    "\n",
    "Ausgabe der Gewichts-Matrizen des trainierten NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Code-Block\n",
    "\n",
    "# Ausgabe der Gewichts-Matrizen\n",
    "best_mlp.coefs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verständnisfragen:\n",
    "\n",
    "1. Zeichne die Struktur deines besten NN.\n",
    "2. Nenne mindestens 3 wichtige Hyperparameter deiner gridSearch.\n",
    "3. Wie viele Neuronen muss die input layer für dieses Problem aufweisen?\n",
    "4. Wie viele Neuronen muss die output layer für dieses Problem aufweisen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
