{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 4.2 - Neuronale Netze am Beispiel Rattern\n",
    "VO Maschinelles Lernen in der Produktion, WS2020/21, Moritz von Unold, Richard Lux, Felix Soest\n",
    "\n",
    "#### In diesem Notebook soll das Verfahren Neuronale Netze anhand des Anwendungsbeispiels Rattern geübt werden.\n",
    "\n",
    "Bei der Fertigung von Bauteilen treten manchmal störende Schwingungen auf, sog. Rattern. Dieses schädigt die Werkzeuge und führt zu einer niedrigeren Bauteilqualität.\n",
    "\n",
    "Im Datensatz \"Rattern\" werden die Drehzahl der Spindel und die Tiefe des Schnitts gemessen. Es soll ein neuronales Netz erstellt werden welches vorhersagen kann bei welcher Drehzahl und Schnitt-Tiefe das sog. Rattern auftritt. \n",
    "### Data-Mining-Prozess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Prozess_Modellentwicklung_v2.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Bibliohteken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Code-Block\n",
    "\n",
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Daten erfassen - Daten importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Code-Block\n",
    "\n",
    "# Erstelle eigene Zufallszahlen\n",
    "my_seed = TODO\n",
    "\n",
    "# Lade Datensatz und Ausgabe Zufallszahl\n",
    "df_train = pd.read_csv(\"Trainingsdaten_Rattern.csv\")\n",
    "df_test = pd.read_csv(\"Testdaten_Rattern.csv\")\n",
    "df = df_train.append(df_test)\n",
    "print(\"\\nGewählte Zahl für Zufallszahlen: \\t\" + str(my_seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Daten erkunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Code-Block\n",
    "\n",
    "# Ausgabe der letzten 5 Zeilen des Datensatzes\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Code-Block\n",
    "\n",
    "# Ausgabe Klassenzugehörigkeit\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "surf = plt.scatter(\n",
    "    df_train[\"Drehzahl Spindel\"],\n",
    "    df_train[\"Tiefe des Schnitts\"],\n",
    "    c=df_train[\"Rattern\"],\n",
    "    cmap=plt.cm.coolwarm,\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "plt.colorbar(surf)\n",
    "plt.xlim(7750, 16250)\n",
    "plt.ylim(0, 0.023)\n",
    "plt.xlabel(\"Drehzahl Spindel\")\n",
    "plt.ylabel(\"Tiefe des Schnitts\")\n",
    "plt.title(\"Effekt des Ratterns über Schnitttiefe und Spindeldrehzahl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Daten vorbereiten - Aufteilung in X und y, Normierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Code-Block\n",
    "\n",
    "# Aufteilen in X und y\n",
    "X_train_, y_train = (\n",
    "    df_train[[\"Drehzahl Spindel\", \"Tiefe des Schnitts\"]],\n",
    "    df_train[\"Rattern\"],\n",
    ")\n",
    "X_test_, y_test = (\n",
    "    df_test[[\"Drehzahl Spindel\", \"Tiefe des Schnitts\"]],\n",
    "    df_test[\"Rattern\"],\n",
    ")\n",
    "\n",
    "# Normiere Input-Parameter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train_), columns=X_train_.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test_), columns=X_test_.columns)\n",
    "\n",
    "\n",
    "# Ausgabe Maximum\n",
    "print(\n",
    "    \"Vor Normierung:\\t\\tDrehzahl min/max: \"\n",
    "    + str(\"%.1f\" % X_train_[\"Drehzahl Spindel\"].min())\n",
    "    + \" / \"\n",
    "    + str(\"%.1f\" % X_train_[\"Drehzahl Spindel\"].max())\n",
    ")\n",
    "print(\n",
    "    \"Nach Normierung:\\tDrehzahl min/max: \"\n",
    "    + str(\"%.1f\" % X_train[\"Drehzahl Spindel\"].min())\n",
    "    + \" / \"\n",
    "    + str(\"%.1f\" % X_train[\"Drehzahl Spindel\"].max())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Modelle bilden - Mögliche Hyperparameter anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Code-Block\n",
    "\n",
    "# Importieren des Modells\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "# Ausgabe möglicher Hyperparameter\n",
    "print(\"\\n Mögliche Hyperparameter (mit Standardeinstellungen) eines Neuronalen Netzes:\")\n",
    "MLPClassifier().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreibung der Hyperparameter:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modelle bilden - Optimale Hyperparameter mittels Gittersuche bestimmen\n",
    "\n",
    "Um die optimalen Hyperparameter für das Neuronale Netz zu finden wird eine __Gittersuche__ durchgeführt:\n",
    "\n",
    "TODO:\n",
    "- Schreibe die zu variierenden Hyperparameter listenweise in ein Dictionary (6. Code-Block - Zeile 5-9)\n",
    "- __Empfehlung:__ Verwende den solver lbfgs (nicht zwingend beste Möglichkeit): 'solver': ['lbfgs'], als random state deinen seed: random_state=my_seed\n",
    "- Die Struktur eines Neuronalen Netzes (Anzahl an hidden layers sowie Neuronen je hidden layer) wird wie folgt angegeben:\n",
    "    - hidden_layers_sizes = (3,) -> 1 hidden layer mit 3 Neuronen\n",
    "    - hidden_layers_sizes = (3,2) -> 2 hidden layers mit 3 und 2 Neuronen\n",
    "    - hidden_layers_sizes = (5,3,5) -> 3 hidden layers mit 5, 3 und 5 Neuronen\n",
    "    - Zur Erinnerung: Die input layer hat soviele Neuronen wir Inputparameter\n",
    "\n",
    "AUSGABE:\n",
    "- Dauer und Anzahl an Kombinationen der Gittersuche sowie Modell mit besten Hyperparametern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Code-Block\n",
    "\n",
    "# Werte für die Gittersuche/Hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "start_timer = time.monotonic()\n",
    "hyper_parameters = [{'hidden_layer_sizes': [TODO], \n",
    "                     TODO,\n",
    "                     TODO,\n",
    "                     TODO,\n",
    "                     'random_state': [my_seed]}]\n",
    "\n",
    "# Berechne Genauigkeit auf Validationsdaten für alle möglichen Kombinationen\n",
    "mlp = MLPClassifier()\n",
    "gridSearch = GridSearchCV(mlp, hyper_parameters, return_train_score=True, cv=5)\n",
    "gridSearch = gridSearch.fit(X_train, y_train)\n",
    "print(\n",
    "    \"\\nDie Gittersuche (\"\n",
    "    + str(len(pd.DataFrame(gridSearch.cv_results_)))\n",
    "    + \" Kombinationen) hat \"\n",
    "    + str(\"%.1f\" % (time.monotonic() - start_timer))\n",
    "    + \" Sekunden gedauert, bestes Modell:\"\n",
    ")\n",
    "gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Code-Block\n",
    "\n",
    "# Ausgabe der Ergebnis-Tabelle der Gittersuche - besten 15 Modelle\n",
    "pd.DataFrame(gridSearch.cv_results_).sort_values(\n",
    "    \"mean_test_score\", ascending=False\n",
    ").head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modell bilden - Vorzugs-Modell erstellen und trainieren\n",
    "\n",
    "Das Modell mit den optimalen Hyperparametern wird erstellt und mit den Trainingsdaten trainiert.\n",
    "\n",
    "TODO.\n",
    "- Schreibe die Code-Zeilen für die Genauigkeit des Modells auf den Trainingsdaten (7. Code-Block - Zeile 10) (Hilfe im Cheat-Sheet Modelle testen)\n",
    "\n",
    "AUSGABE:\n",
    "- Genauigkeit auf Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Code-Block\n",
    "\n",
    "# Erstellen des Modells mit den besten Hyperparametern aus der gridSearch => gridSearch.best_estimator_\n",
    "best_mlp = gridSearch.best_estimator_\n",
    "\n",
    "# Ausgabe Genauigkeit auf Trainingsdaten\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Modell testen & anwenden - Bewertung des Modells - Genauigkeit auf Testdaten\n",
    "\n",
    "Um die Qualität/Güte des Modells zu bestimmen wird die Genauigkeit auf den Testdaten berechnet (Hilfe im Cheat-Sheet Modelle_testen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Code-Block\n",
    "\n",
    "# Berechne Genauigkeit auf Testdaten\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Modell testen & anwenden - Bewertung des Modells - Konfusionsmatrix\n",
    "\n",
    "Um die Modellgüte visuell darzustellen wird eine Wahrheitsmatrix erstellt.\n",
    "\n",
    "TODO:\n",
    "- Schreibe die Code-Zeilen um die Wahrheitsmatrix des Modells auf den Testdaten anzuzeigen (Hilfe im Cheat-Sheet Modelle_testen).\n",
    "\n",
    "AUSGABE:\n",
    "- Konfusionsmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Code-Block\n",
    "\n",
    "# Ausgabe Konfusionsmatrix\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Modell testen & anwenden - Modell visualisieren\n",
    "\n",
    "Da das Modell nur 2 Input-Parameter benötigt können wir alle möglichen Modell-Vorhersagen grafisch visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Code-Block\n",
    "\n",
    "# Erstelle Grid für Modellausgabe\n",
    "x = np.linspace(-0.1, 1.1, 200)\n",
    "y = np.linspace(-0.1, 1.1, 200)\n",
    "\n",
    "# Berechne Modellvorhersage\n",
    "z = []\n",
    "for x_ in x:\n",
    "    for y_ in y:\n",
    "        z.append(best_mlp.predict(np.asarray([y_, x_]).reshape(1, -1)))\n",
    "\n",
    "# Ausgabe Modellvorhersage\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.asarray(z).reshape(200, 200)\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "plt.title(\n",
    "    \"Modellvorhersage und Datensätze (Train = Kreis, Valid = Viereck, Test = Raute)\"\n",
    ")\n",
    "plt.xlabel(\"Drehzahl Spindel\")\n",
    "plt.ylabel(\"Tiefe des Schnitts\")\n",
    "surf = plt.contourf(X, Y, Z, cmap=plt.cm.coolwarm)\n",
    "plt.scatter(\n",
    "    X_train[\"Drehzahl Spindel\"],\n",
    "    X_train[\"Tiefe des Schnitts\"],\n",
    "    c=y_train,\n",
    "    marker=\"o\",\n",
    "    alpha=0.3,\n",
    "    edgecolors=\"black\",\n",
    "    s=70,\n",
    ")\n",
    "plt.scatter(\n",
    "    X_test[\"Drehzahl Spindel\"],\n",
    "    X_test[\"Tiefe des Schnitts\"],\n",
    "    c=y_test,\n",
    "    marker=\"D\",\n",
    "    edgecolors=\"black\",\n",
    "    s=70,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Modell testen & anwenden - Modell analysieren\n",
    "\n",
    "Ausgabe der trainierten Gewichte (Gewichtsmatrizen) des neuronalen Netzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Code-Block\n",
    "\n",
    "# Ausgabe der Gewichte\n",
    "best_mlp.coefs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verständnisfragen:\n",
    "\n",
    "1. Vergleiche für dieses Problem (Rattern) die Modelle SVM und NN in Bezug auf: Aufwand der Erstellung/GridSearch, komplexität des Modells bzw. der Hyperparameter und das Ergebnis (Genauigkeit und Bild aus 6.3) -> Würdest du das nächste mal ein SVM-Modell oder ein NN-Modell wählen?\n",
    "2. Wie viele Neuronen besitzt die output layer für dieses Problem? Wie kann daraus die resultierende Klasse gewählt werden?\n",
    "3. Welche der folgenden Einstellungen haben einen Einfluss auf die Dauer der GridSearch?\n",
    "    - Anzahl an variierenden Hyperparametern\n",
    "    - Größe der Trainingsdaten\n",
    "    - Anzahl an Splits der Cross-Validation (hier standardmässig auf 3 gesetzt)\n",
    "    - Größe der Testdaten\n",
    "    - Anzahl an Werten je Hyperparametern\n",
    "    - Komplexität des gesuchten Zusammenhangs\n",
    "    - Größe der Validierungsdaten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
